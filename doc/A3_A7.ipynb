{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# import relevant libraries\n",
        "import numpy as np\n",
        "import matplotlib as plt\n",
        "import scipy\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch as t\n",
        "import torch.nn as nn\n",
        "import warnings\n",
        "import math\n",
        "import itertools\n",
        "import copy\n",
        "from datetime import datetime, timedelta\n",
        "from sklearn.metrics import mutual_info_score\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "uJK7CBt7k4SK"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import data\n",
        "compas_url = \"https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv\"\n",
        "\n",
        "data = pd.read_csv(compas_url)"
      ],
      "metadata": {
        "id": "2BUxp1qnx6Ww"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project 4 Goals:\n",
        "\n",
        "\n",
        "*   Task A3: Maximizing fairness under accuracy constraints (gamma and Fine-gamma).\n",
        "*   Task A7: Information Theoretic Measures for Fairness-aware Feature selection (FFS).\n",
        "*   Compare gamma, Fine-gamma and FFS.\n",
        "\n"
      ],
      "metadata": {
        "id": "QfPvsB-VhTsA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task A3: Maximizing fairness under accuracy constraints (gamma and Fine-gamma)"
      ],
      "metadata": {
        "id": "HNz9sqR2jmTy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "refer to this github, section 1.4: https://github.com/mbilalzafar/fair-classification/tree/master/disparate_impact"
      ],
      "metadata": {
        "id": "MCd-4k2VnRSW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training an unconstrained classifier on the biased data\n",
        "\n",
        "*   We will train a logistic regression classifier on the data to see the correlations between the classifier decisions and sensitive feature value: **race.**"
      ],
      "metadata": {
        "id": "RyJRzSiUjcGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting features for the model\n",
        "\n",
        "unprocessed_features = ['age', 'c_charge_degree', 'age_cat', 'sex',\n",
        "                        'priors_count', 'is_recid', 'c_jail_in', 'c_jail_out']\n",
        "\n",
        "target = 'two_year_recid'\n",
        "\n",
        "sensitive_attr = 'race'\n",
        "\n",
        "data_full = data[unprocessed_features + [target, sensitive_attr]]\n",
        "\n",
        "# 2. Feature Encoding\n",
        "\n",
        "def encode_features(df):\n",
        "    race_mapping = {'African-American': 0, 'Caucasian': 1}\n",
        "    sex_mapping = {'Male': 1, 'Female': 0}\n",
        "    age_cat_mapping = {'Less than 25': 0, '25 - 45': 1, 'Greater than 45': 2}\n",
        "    c_charge_degree_mapping = {'F': 0, 'M': 1}\n",
        "\n",
        "    # Keep records for African-American and Caucasian\n",
        "    df_filtered = df[df['race'].isin(race_mapping.keys())]\n",
        "    print(\"Shape after filtering for race:\", df_filtered.shape)\n",
        "\n",
        "    df_filtered['race'] = df_filtered['race'].map(race_mapping)\n",
        "    df_filtered['sex'] = df_filtered['sex'].map(sex_mapping)\n",
        "    df_filtered['age_cat'] = df_filtered['age_cat'].map(age_cat_mapping)\n",
        "    df_filtered['c_charge_degree'] = df_filtered['c_charge_degree'].map(c_charge_degree_mapping)\n",
        "\n",
        "    return df_filtered\n",
        "\n",
        "processed_data = encode_features(data_full)\n",
        "\n",
        "# 3. Calculating Length of Stay\n",
        "processed_data['c_jail_in'] = pd.to_datetime(processed_data['c_jail_in'])\n",
        "processed_data['c_jail_out'] = pd.to_datetime(processed_data['c_jail_out'])\n",
        "processed_data['length_of_stay'] = (processed_data['c_jail_out'] - processed_data['c_jail_in']).dt.days\n",
        "\n",
        "# Apply the specified bins to the length of stay\n",
        "processed_data['length_of_stay'] = processed_data['length_of_stay'].apply(\n",
        "    lambda days: 0 if days <= 7 else (2 if days > 90 else 1)\n",
        ")\n",
        "\n",
        "# 5. Processing Prior Crime Counts\n",
        "processed_data['priors_count'] = processed_data['priors_count'].apply(\n",
        "    lambda count: 0 if count == 0 else (2 if count > 3 else 1)\n",
        ")\n",
        "\n",
        "processed_features = ['age_cat', 'c_charge_degree', 'sex', 'priors_count',\n",
        "                      'length_of_stay']\n",
        "\n",
        "x = processed_data[processed_features]\n",
        "\n",
        "y = processed_data[target]\n",
        "\n",
        "a = processed_data[sensitive_attr]\n",
        "\n",
        "# Splitting the data into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Retraining the unconstrained logistic regression classifier\n",
        "clf_unconstrained = LogisticRegression(solver='liblinear')\n",
        "clf_unconstrained.fit(x_train, y_train)\n",
        "\n",
        "# Predicting on the test set\n",
        "y_pred_unconstrained = clf_unconstrained.predict(x_test)\n",
        "\n",
        "# Calculating accuracy\n",
        "accuracy_unconstrained = accuracy_score(y_test, y_pred_unconstrained)\n",
        "\n",
        "# Including the 'race' column in the test data for analysis\n",
        "data_test = pd.concat([x_test, a.loc[x_test.index], y_test], axis=1)\n",
        "\n",
        "# Calculating p-rule and covariance\n",
        "protected_group = data_test[sensitive_attr] == 0\n",
        "non_protected_group = data_test[sensitive_attr] == 1\n",
        "\n",
        "protected_positive_rate = np.mean(y_pred_unconstrained[protected_group])\n",
        "non_protected_positive_rate = np.mean(y_pred_unconstrained[non_protected_group])\n",
        "\n",
        "p_rule = min(protected_positive_rate / non_protected_positive_rate,\n",
        "             non_protected_positive_rate / protected_positive_rate) * 100\n",
        "\n",
        "race_binary = (data_test[sensitive_attr] == 0)\n",
        "\n",
        "covariance = np.cov(race_binary, y_pred_unconstrained)[0, 1]\n",
        "\n",
        "# Output results\n",
        "accuracy_unconstrained, p_rule, covariance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-7j1gDsyLqz",
        "outputId": "1477f865-6273-4e70-e20c-b20c37b2df35"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape after filtering for race: (6150, 10)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6601626016260163, 48.83463665840168, 0.05913708269403738)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following output is generated by the program:"
      ],
      "metadata": {
        "id": "6L6Bxz2rkPdn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy:** The accuracy of the classifier on the test set is approximately **68.64%**.\n",
        "\n",
        "**P-Rule:** The p-rule for different race categories achieved is about **52.60%**. The p-rule is a measure of fairness, specifically a comparison of positive outcomes between the protected group (in this case, African-Americans) and the non-protected group. A p-rule of approximately 52.60% suggests that the classifier's decisions are somewhat biased *against* the protected group.\n",
        "\n",
        "These results imply that the classifier, when trained without fairness constraints, reflects the biases present in the data. This analysis sets the stage for training classifiers with fairness constraints to see if the fairness can be improved while maintaining acceptable accuracy."
      ],
      "metadata": {
        "id": "5Rfa473lj4NS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimizing fairness subject to accuracy constraints (gamma and Fine-gamma)\n",
        "\n",
        "*   Let's try to optimize fairness (that does not necessarily correspond to a 100% p-rule) subject to a deterministic loss in accuracy."
      ],
      "metadata": {
        "id": "yq-gZTogiHrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize_fairness_with_accuracy_constraints(model, x_test, y_test, sensitive_attr_binary, gamma=0):\n",
        "    \"\"\"\n",
        "    Optimize fairness subject to accuracy constraints.\n",
        "    Adjusts the decision threshold of the logistic regression model to balance fairness and accuracy.\n",
        "    \"\"\"\n",
        "    initial_accuracy = accuracy_score(y_test, model.predict(x_test))\n",
        "    target_accuracy = initial_accuracy * (1 - gamma)\n",
        "    thresholds = np.linspace(0, 1, 1001)\n",
        "\n",
        "    best_threshold = 0.5  # Initial decision threshold\n",
        "    best_p_rule = 0\n",
        "    best_covariance = float('inf')\n",
        "    best_accuracy = initial_accuracy\n",
        "\n",
        "    for threshold in thresholds:\n",
        "        # Apply the threshold\n",
        "        y_pred_adjusted = (model.predict_proba(x_test)[:, 1] >= threshold).astype(int)\n",
        "\n",
        "        # Calculate accuracy\n",
        "        current_accuracy = accuracy_score(y_test, y_pred_adjusted)\n",
        "        if current_accuracy < target_accuracy:\n",
        "            continue  # Skip if accuracy constraint is not met\n",
        "\n",
        "        # Calculate p-rule\n",
        "        protected_positive_rate = np.mean(y_pred_adjusted[sensitive_attr_binary == 1])\n",
        "        non_protected_positive_rate = np.mean(y_pred_adjusted[sensitive_attr_binary == 0])\n",
        "        if non_protected_positive_rate == 0:  # Avoid division by zero\n",
        "            continue\n",
        "\n",
        "        current_p_rule = min(protected_positive_rate / non_protected_positive_rate,\n",
        "                             non_protected_positive_rate / protected_positive_rate) * 100\n",
        "\n",
        "        # Calculate covariance\n",
        "        current_covariance = np.cov(sensitive_attr_binary, y_pred_adjusted)[0, 1]\n",
        "\n",
        "        # Update the best threshold if it has higher p-rule or lower covariance\n",
        "        if current_p_rule > best_p_rule or (current_p_rule == best_p_rule and abs(current_covariance) < abs(best_covariance)):\n",
        "            best_threshold = threshold\n",
        "            best_p_rule = current_p_rule\n",
        "            best_accuracy = current_accuracy\n",
        "            best_covariance = current_covariance\n",
        "\n",
        "    return best_threshold, best_accuracy, best_p_rule, best_covariance\n",
        "\n",
        "# Extracting the binary sensitive attribute (0 for African-American, 1 for white)\n",
        "sensitive_attr_binary = (data_test[sensitive_attr] == 0)\n",
        "\n",
        "# Optimizing fairness with strict accuracy constraint\n",
        "gamma_value = 0\n",
        "best_threshold, acc_fairness_optimized, p_rule_fairness_optimized, covariance_fairness_optimized = optimize_fairness_with_accuracy_constraints(\n",
        "    clf_unconstrained, x_test, y_test, sensitive_attr_binary, gamma=gamma_value\n",
        ")\n",
        "\n",
        "best_threshold, acc_fairness_optimized, p_rule_fairness_optimized, covariance_fairness_optimized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgwCcMfNynlC",
        "outputId": "00cf4df3-e850-4600-e515-6615f1156dfd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.464, 0.6644986449864498, 54.87236695321215, 0.060640530483396106)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy: The accuracy with this threshold is about **66.45%**, which is actually slightly than the unconstrained model. This change in accuracy is within the bounds of the 0% loss we are willing to accept (as dictated by gamma = 0).\n",
        "\n",
        "P-Rule: The p-rule achieved is **54.87%**, indicating a slightly improved level of fairness according to this metric."
      ],
      "metadata": {
        "id": "TqitnZKCyw5W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The \"gamma\" variable controls how much loss in accuracy we are willing to take while optimizing for fairness. A larger value of gamma will result in more fair system, but we will be getting a more loss in accuracy."
      ],
      "metadata": {
        "id": "ubOVxLWji2Gb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PLOT THE RESULTS\n",
        "\n",
        "results = []\n",
        "\n",
        "for gamma_value in np.arange(0, 0.26, 0.01):\n",
        "    best_threshold, acc_fairness_optimized, p_rule_fairness_optimized, covariance_fairness_optimized = optimize_fairness_with_accuracy_constraints(\n",
        "        clf_unconstrained, x_test, y_test, sensitive_attr_binary, gamma=gamma_value\n",
        "    )\n",
        "\n",
        "    result_dict = {\n",
        "        'gamma': gamma_value,\n",
        "        'best_threshold': best_threshold,\n",
        "        'acc_fairness_optimized': acc_fairness_optimized,\n",
        "        'p_rule_fairness_optimized': p_rule_fairness_optimized,\n",
        "        'covariance_fairness_optimized': covariance_fairness_optimized\n",
        "    }\n",
        "\n",
        "    results.append(result_dict)"
      ],
      "metadata": {
        "id": "IwrpBW-UzdvJ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract values for plotting\n",
        "gammas = [result['gamma'] for result in results]\n",
        "acc_fairness_optimized_values = [result['acc_fairness_optimized'] for result in results]\n",
        "p_rule_fairness_optimized_values = [result['p_rule_fairness_optimized'] for result in results]\n",
        "\n",
        "# Plotting\n",
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "ax1.set_xlabel('Gamma')\n",
        "ax1.set_ylabel('Accuracy (Fairness Optimized)', color='tab:blue')\n",
        "ax1.plot(gammas, acc_fairness_optimized_values, color='tab:blue')\n",
        "ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "ax2.set_ylabel('P-rule (Fairness Optimized)', color='tab:red')\n",
        "ax2.plot(gammas, p_rule_fairness_optimized_values, color='tab:red')\n",
        "ax2.tick_params(axis='y', labelcolor='tab:red')\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.title('Accuracy and P-rule vs. Gamma')\n",
        "plt.savefig('Accuracy_PRule_vs_Gamma.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        },
        "id": "FPG2ZRfazkPj",
        "outputId": "3e4df5eb-6312-4da2-e004-0a948b864bc7"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can clearly see that *as gamma increases, the accuracy of our classifier decreases* while the p-rule that it satisfies increases. If we wanted our p-rule of fairness to equal 80%, say, we would have to contend with a reduction in the model accuracy rate, which would move from ~66% to ~55%."
      ],
      "metadata": {
        "id": "TKBr5bbhzvTU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we choose \"sex\" as the sensitive attribute."
      ],
      "metadata": {
        "id": "dVz1_54Z33JE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sensitive_attr_sex = 'sex'\n",
        "features = ['age', 'priors_count']\n",
        "\n",
        "# Preprocessing with 'sex' as the sensitive attribute\n",
        "data_preprocessed_sex = pd.get_dummies(data[features + [sensitive_attr_sex]])\n",
        "x_sex = data_preprocessed_sex.drop(columns=[sensitive_attr_sex + '_Female', sensitive_attr_sex + '_Male'])\n",
        "y_sex = data[target]\n",
        "\n",
        "# Splitting the data into training and testing sets for 'sex'\n",
        "x_train_sex, x_test_sex, y_train_sex, y_test_sex = train_test_split(x_sex, y_sex, test_size=0.3, random_state=42)\n",
        "\n",
        "# Training the unconstrained logistic regression classifier with 'sex' as sensitive attribute\n",
        "clf_unconstrained_sex = LogisticRegression(solver='liblinear')\n",
        "clf_unconstrained_sex.fit(x_train_sex, y_train_sex)\n",
        "\n",
        "# Predicting on the test set\n",
        "y_pred_unconstrained_sex = clf_unconstrained_sex.predict(x_test_sex)\n",
        "\n",
        "# Calculating accuracy\n",
        "accuracy_unconstrained_sex = accuracy_score(y_test_sex, y_pred_unconstrained_sex)\n",
        "\n",
        "# Including the 'sex' column in the test data for analysis\n",
        "data_test_sex = pd.concat([x_test_sex, data.loc[x_test_sex.index, sensitive_attr_sex], y_test_sex], axis=1)\n",
        "\n",
        "# Calculating p-rule and covariance for 'sex'\n",
        "protected_group_sex = data_test_sex[sensitive_attr_sex] == 'Female'\n",
        "non_protected_group_sex = data_test_sex[sensitive_attr_sex] != 'Female'\n",
        "\n",
        "protected_positive_rate_sex = np.mean(y_pred_unconstrained_sex[protected_group_sex])\n",
        "non_protected_positive_rate_sex = np.mean(y_pred_unconstrained_sex[non_protected_group_sex])\n",
        "\n",
        "p_rule_sex = min(protected_positive_rate_sex / non_protected_positive_rate_sex,\n",
        "                 non_protected_positive_rate_sex / protected_positive_rate_sex) * 100\n",
        "\n",
        "sex_binary = (data_test_sex[sensitive_attr_sex] == 'Female').astype(int)\n",
        "covariance_sex = np.cov(sex_binary, y_pred_unconstrained_sex)[0, 1]\n",
        "\n",
        "accuracy_unconstrained_sex, p_rule_sex, covariance_sex"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpd2XBnR34Ha",
        "outputId": "18075a52-d695-4b13-dcad-041f71e98153"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6849884526558891, 61.09848252134914, -0.021624482930848257)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy: The accuracy of the classifier on the test set is approximately **68.50%.**\n",
        "\n",
        "P-Rule: The p-rule achieved for difference in sex is about **61.10%**. This metric measures fairness in terms of the ratio of positive outcomes between the protected group (in this case, females) and the non-protected group (males). A p-rule of approximately 61.10% suggests that there is some bias in the classifier's decisions, though it is less pronounced than with the race attribute."
      ],
      "metadata": {
        "id": "siGB1Zal37gg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting features for the model - for simplicity, we use a few features\n",
        "target = 'two_year_recid'\n",
        "sensitive_attr_sex = 'sex'\n",
        "\n",
        "# Preprocessing with 'sex' as the sensitive attribute\n",
        "data_preprocessed_sex = pd.get_dummies(data[features + [sensitive_attr_sex]])\n",
        "x_sex = data_preprocessed_sex.drop(columns=[sensitive_attr_sex + '_Female', sensitive_attr_sex + '_Male'])\n",
        "y_sex = data[target]\n",
        "\n",
        "# Splitting the data into training and testing sets for 'sex'\n",
        "x_train_sex, x_test_sex, y_train_sex, y_test_sex = train_test_split(x_sex, y_sex, test_size=0.3, random_state=42)\n",
        "\n",
        "# Training the unconstrained logistic regression classifier with 'sex' as sensitive attribute\n",
        "clf_unconstrained_sex = LogisticRegression(solver='liblinear')\n",
        "clf_unconstrained_sex.fit(x_train_sex, y_train_sex)\n",
        "\n",
        "# Including the 'sex' column in the test data for analysis\n",
        "data_test_sex = pd.concat([x_test_sex, data.loc[x_test_sex.index, sensitive_attr_sex], y_test_sex], axis=1)\n",
        "\n",
        "# Extracting the binary sensitive attribute for 'sex' (1 for Female, 0 for Male)\n",
        "sensitive_attr_binary_sex = (data_test_sex[sensitive_attr_sex] == 'Female').astype(int)\n",
        "\n",
        "# Function to optimize fairness with accuracy constraints for 'sex'\n",
        "def optimize_fairness_sex_with_accuracy_constraints(model, x_test, y_test, sensitive_attr_binary, gamma=0.5):\n",
        "    initial_accuracy = accuracy_score(y_test, model.predict(x_test))\n",
        "    target_accuracy = initial_accuracy * (1 - gamma)\n",
        "    thresholds = np.linspace(0, 1, 100)\n",
        "\n",
        "    best_threshold = 0.5  # Initial decision threshold\n",
        "    best_p_rule = 0\n",
        "    best_covariance = float('inf')\n",
        "    best_accuracy = initial_accuracy\n",
        "\n",
        "    for threshold in thresholds:\n",
        "        y_pred_adjusted = (model.predict_proba(x_test)[:, 1] >= threshold).astype(int)\n",
        "        current_accuracy = accuracy_score(y_test, y_pred_adjusted)\n",
        "        if current_accuracy < target_accuracy:\n",
        "            continue\n",
        "\n",
        "        protected_positive_rate = np.mean(y_pred_adjusted[sensitive_attr_binary == 1])\n",
        "        non_protected_positive_rate = np.mean(y_pred_adjusted[sensitive_attr_binary == 0])\n",
        "        if non_protected_positive_rate == 0:\n",
        "            continue\n",
        "\n",
        "        current_p_rule = min(protected_positive_rate / non_protected_positive_rate,\n",
        "                             non_protected_positive_rate / protected_positive_rate) * 100\n",
        "\n",
        "        current_covariance = np.cov(sensitive_attr_binary, y_pred_adjusted)[0, 1]\n",
        "\n",
        "        if current_p_rule > best_p_rule or (current_p_rule == best_p_rule and abs(current_covariance) < abs(best_covariance)):\n",
        "            best_threshold = threshold\n",
        "            best_p_rule = current_p_rule\n",
        "            best_accuracy = current_accuracy\n",
        "            best_covariance = current_covariance\n",
        "\n",
        "    return best_threshold, best_accuracy, best_p_rule, best_covariance\n",
        "\n",
        "# Optimizing fairness with accuracy constraint for 'sex'\n",
        "gamma_value_sex = 0.2\n",
        "best_threshold_sex, acc_fairness_optimized_sex, p_rule_fairness_optimized_sex, covariance_fairness_optimized_sex = optimize_fairness_sex_with_accuracy_constraints(\n",
        "    clf_unconstrained_sex, x_test_sex, y_test_sex, sensitive_attr_binary_sex, gamma=gamma_value_sex\n",
        ")\n",
        "\n",
        "best_threshold_sex, acc_fairness_optimized_sex, p_rule_fairness_optimized_sex, covariance_fairness_optimized_sex"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-ZXUT354FYy",
        "outputId": "42170835-de42-4b77-c83b-fbd72c473dcf"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.30303030303030304,\n",
              " 0.5547344110854503,\n",
              " 94.85804669182075,\n",
              " -0.006300452929098003)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy: The accuracy of the classifier with this threshold is about **55.47%.** This is higher than the accuracy we observed with gamma set to 0.3, reflecting the less stringent loss in accuracy we are willing to accept with gamma at 0.2.\n",
        "\n",
        "P-Rule: The p-rule achieved is approximately **94.86%**, indicating a high level of fairness."
      ],
      "metadata": {
        "id": "NOHk8IbB4HHg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapping age categories\n",
        "age_cat_mapping = {'Less than 25': 0, '25 - 45': 1, 'Greater than 45': 2}\n",
        "data['age_cat_mapped'] = data['age_cat'].map(age_cat_mapping)\n",
        "\n",
        "# Selecting features for the model, excluding 'age' as it is represented by 'age_cat_mapped'\n",
        "features_age_sensitive = ['sex', 'priors_count', 'age_cat_mapped']\n",
        "sensitive_attr_age = 'age_cat_mapped'\n",
        "\n",
        "# Preprocessing with 'age_cat_mapped' as the sensitive attribute\n",
        "data_preprocessed_age = pd.get_dummies(data[features_age_sensitive])\n",
        "x_age = data_preprocessed_age.drop(columns=['age_cat_mapped'])\n",
        "y_age = data[target]\n",
        "\n",
        "# Splitting the data into training and testing sets for 'age_cat_mapped'\n",
        "x_train_age, x_test_age, y_train_age, y_test_age = train_test_split(x_age, y_age, test_size=0.3, random_state=42)\n",
        "\n",
        "# Training the unconstrained logistic regression classifier with 'age_cat_mapped' as sensitive attribute\n",
        "clf_unconstrained_age = LogisticRegression(solver='liblinear')\n",
        "clf_unconstrained_age.fit(x_train_age, y_train_age)\n",
        "\n",
        "# Predicting on the test set\n",
        "y_pred_unconstrained_age = clf_unconstrained_age.predict(x_test_age)\n",
        "\n",
        "# Calculating accuracy\n",
        "accuracy_unconstrained_age = accuracy_score(y_test_age, y_pred_unconstrained_age)\n",
        "\n",
        "# Including the 'age_cat_mapped' column in the test data for analysis\n",
        "data_test_age = pd.concat([x_test_age, data.loc[x_test_age.index, sensitive_attr_age], y_test_age], axis=1)\n",
        "\n",
        "# Calculating p-rule and covariance for 'age_cat_mapped'\n",
        "# Here, we consider each age category as a protected group one at a time\n",
        "p_rules_age = {}\n",
        "covariances_age = {}\n",
        "for age_group in age_cat_mapping.values():\n",
        "    protected_group_age = data_test_age[sensitive_attr_age] == age_group\n",
        "    non_protected_group_age = data_test_age[sensitive_attr_age] != age_group\n",
        "\n",
        "    protected_positive_rate_age = np.mean(y_pred_unconstrained_age[protected_group_age])\n",
        "    non_protected_positive_rate_age = np.mean(y_pred_unconstrained_age[non_protected_group_age])\n",
        "\n",
        "    p_rules_age[age_group] = min(protected_positive_rate_age / non_protected_positive_rate_age,\n",
        "                                 non_protected_positive_rate_age / protected_positive_rate_age) * 100\n",
        "\n",
        "    age_binary = (data_test_age[sensitive_attr_age] == age_group).astype(int)\n",
        "    covariances_age[age_group] = np.cov(age_binary, y_pred_unconstrained_age)[0, 1]\n",
        "\n",
        "accuracy_unconstrained_age, p_rules_age, covariances_age"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkovDBBq4L0B",
        "outputId": "8e9a29f5-f353-4fd8-8c46-266362df4276"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6475750577367205,\n",
              " {0: 32.850691864274125, 1: 65.0253908496099, 2: 83.14940057425123},\n",
              " {0: -0.03259659428054287, 1: 0.024667346842943305, 2: 0.00792924743759951})"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy: The accuracy of the classifier on the test set is approximately **64.76%.**\n",
        "\n",
        "P-Rule for Different Age Categories: For the group 'Less than 25': The p-rule is about **32.85%**, indicating a significant bias against this age group.\n",
        "For the group '25 - 45': The p-rule is about 65.03%, suggesting some bias but less severe than the youngest group.\n",
        "For the group 'Greater than 45': The p-rule is about 83.15%, indicating relatively less bias compared to the other groups.\n",
        "Covariance between Age Categories and Decision Boundary:\n",
        "\n",
        "For the group 'Less than 25': The covariance is approximately -0.0326, indicating a negative correlation between being in this age group and receiving a positive decision.\n",
        "For the group '25 - 45': The covariance is approximately 0.0247, suggesting a slight positive correlation.\n",
        "For the group 'Greater than 45': The covariance is approximately 0.0079, indicating a very small positive correlation."
      ],
      "metadata": {
        "id": "sUZqPKvt4QID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize_fairness_age_with_accuracy_constraints(model, x_test, y_test, sensitive_attr_data, age_categories, gamma=0.15):\n",
        "    \"\"\"\n",
        "    Optimize fairness with respect to age categories subject to accuracy constraints.\n",
        "    \"\"\"\n",
        "    initial_accuracy = accuracy_score(y_test, model.predict(x_test))\n",
        "    target_accuracy = initial_accuracy * (1 - gamma)\n",
        "    thresholds = np.linspace(0, 1, 100)\n",
        "\n",
        "    best_results = {}\n",
        "\n",
        "    for age_group in age_categories:\n",
        "        best_threshold = 0.5  # Initial decision threshold\n",
        "        best_p_rule = 0\n",
        "        best_covariance = float('inf')\n",
        "        best_accuracy = initial_accuracy\n",
        "\n",
        "        for threshold in thresholds:\n",
        "            # Apply the threshold\n",
        "            y_pred_adjusted = (model.predict_proba(x_test)[:, 1] >= threshold).astype(int)\n",
        "\n",
        "            # Calculate accuracy\n",
        "            current_accuracy = accuracy_score(y_test, y_pred_adjusted)\n",
        "            if current_accuracy < target_accuracy:\n",
        "                continue  # Skip if accuracy constraint is not met\n",
        "\n",
        "            # Calculate p-rule and covariance for the current age group\n",
        "            protected_group = sensitive_attr_data == age_group\n",
        "            non_protected_group = sensitive_attr_data != age_group\n",
        "\n",
        "            protected_positive_rate = np.mean(y_pred_adjusted[protected_group])\n",
        "            non_protected_positive_rate = np.mean(y_pred_adjusted[non_protected_group])\n",
        "            if non_protected_positive_rate == 0:  # Avoid division by zero\n",
        "                continue\n",
        "\n",
        "            current_p_rule = min(protected_positive_rate / non_protected_positive_rate,\n",
        "                                 non_protected_positive_rate / protected_positive_rate) * 100\n",
        "            current_covariance = np.cov(protected_group, y_pred_adjusted)[0, 1]\n",
        "\n",
        "            # Update the best threshold if it has higher p-rule or lower covariance\n",
        "            if current_p_rule > best_p_rule or (current_p_rule == best_p_rule and abs(current_covariance) < abs(best_covariance)):\n",
        "                best_threshold = threshold\n",
        "                best_p_rule = current_p_rule\n",
        "                best_accuracy = current_accuracy\n",
        "                best_covariance = current_covariance\n",
        "\n",
        "        best_results[age_group] = {\n",
        "            'threshold': best_threshold,\n",
        "            'accuracy': best_accuracy,\n",
        "            'p_rule': best_p_rule,\n",
        "            'covariance': best_covariance\n",
        "        }\n",
        "\n",
        "    return best_results\n",
        "\n",
        "# Optimizing fairness with accuracy constraint for 'age_cat_mapped'\n",
        "gamma_value_age = 0.15\n",
        "optimized_results_age = optimize_fairness_age_with_accuracy_constraints(\n",
        "    clf_unconstrained_age, x_test_age, y_test_age, data_test_age[sensitive_attr_age], age_cat_mapping.values(), gamma=gamma_value_age\n",
        ")\n",
        "\n",
        "optimized_results_age"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGYpUCAk4Uxc",
        "outputId": "d7255cba-158a-4777-834c-27d693e65c5c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: {'threshold': 0.38383838383838387,\n",
              "  'accuracy': 0.5981524249422633,\n",
              "  'p_rule': 80.32585252450748,\n",
              "  'covariance': -0.021748494149488005},\n",
              " 1: {'threshold': 0.797979797979798,\n",
              "  'accuracy': 0.5796766743648961,\n",
              "  'p_rule': 98.67822318526544,\n",
              "  'covariance': 0.00011718099661475575},\n",
              " 2: {'threshold': 0.37373737373737376,\n",
              "  'accuracy': 0.5939953810623556,\n",
              "  'p_rule': 97.92574724448001,\n",
              "  'covariance': 0.00222451793573615}}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Age Group 'Less than 25':\n",
        "\n",
        "Best Decision Threshold: Approximately **0.384.**\n",
        "Accuracy: About **59.82%.**\n",
        "P-Rule: Approximately **80.33%**, indicating improved fairness compared to the unconstrained model.\n",
        "\n",
        "\n",
        "Age Group '25 - 45':\n",
        "Best Decision Threshold: Approximately **0.798.**\n",
        "Accuracy: About** 57.97%.**\n",
        "P-Rule: Approximately **98.68%**, indicating very high fairness.\n",
        "\n",
        "Best Decision Threshold: Approximately **0.374.**\n",
        "Accuracy: About **59.40%**.\n",
        "P-Rule: Approximately **97.93%**, also indicating very high fairness.\n",
        "Covariance: Approximately **0.0022**, indicating a minimal positive correlation.\n",
        "\n",
        "These results demonstrate that with a gamma value of **0.15**, the model achieves a better balance between fairness and accuracy across different age groups compared to the unconstrained model. The p-rule values are significantly higher, suggesting less bias, especially for the younger age group, which had the most significant bias in the unconstrained model."
      ],
      "metadata": {
        "id": "Z6H5cx894ZAP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task A7: Information Theoretic Measures for Fairness-aware Feature selection (FFS)"
      ],
      "metadata": {
        "id": "XbA2GIqAkX5e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "referring to this link: https://arxiv.org/abs/2106.00772"
      ],
      "metadata": {
        "id": "5fp3JcEooL8Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bivariate decomposition of mutual information**:\n",
        "\n",
        "$I(T; R_1, R_2) = UI(T;R_1 \\setminus R_2) + UI(T; R_2 \\setminus R_1) + SI(T; R_1, R_2) + CI(T; R_1, R_2)$\n",
        "\n",
        "mutual information between random variable $T$ and random variables $R_1$ and $R_2$ \\\\\n",
        "= unique information shared between $T$ and $R_1$ but not $R_2$ \\\\\n",
        "$+$ unique information shared between $T$ and $R_2$ but not $R_1$ \\\\\n",
        "$+$ shared information between $T$, $R_1$, and $R_2$ \\\\\n",
        "$+$ synergistic information between $T$, $R_1$, and $R_2$\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cmVSYaa2OHMA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Generalized formula) \\\\\n",
        "$I(T; R_i) = UI(T; R_i \\setminus R_j) + SI(T; R_1, R_2), \\quad i \\neq j, \\quad i, j \\in \\{1,2\\}$\n",
        "\n",
        "mutual information between $T$ and one of the random variables $R_i$ where $i$ can be either 1 or 2 \\\\\n",
        "= unique information shared between $T$ and $R_i$ but not $R_j$, where $i \\neq j$ and both $i$ and $j$ can be 1 or 2 \\\\\n",
        "$+$ shared information between $T$, $R_1$, and $R_2$"
      ],
      "metadata": {
        "id": "TahxYbTjOy3P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In our study, $T$ is recidivism (\"whether or not the defendant recidivated within two years\") and $R_i$ is the defendent's race (Caucasian or African-American)."
      ],
      "metadata": {
        "id": "oXNrqWtoUiUU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Pre-processing"
      ],
      "metadata": {
        "id": "a1-ElUBp0y5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Data Import and Selection\n",
        "columns_required = [\n",
        "    'age', 'c_charge_degree', 'race', 'age_cat', 'sex',\n",
        "    'priors_count', 'is_recid', 'two_year_recid',\n",
        "    'c_jail_in', 'c_jail_out'\n",
        "]\n",
        "\n",
        "print(\"Initial dataset shape:\", data.shape)\n",
        "\n",
        "# Checking the unique values of race to ensure all necessary mappings are accounted for\n",
        "print(\"Unique race values in dataset:\", data['race'].unique())\n",
        "\n",
        "# 2. Feature Encoding\n",
        "def encode_features(df):\n",
        "    race_mapping = {'African-American': 0, 'Caucasian': 1}\n",
        "    sex_mapping = {'Male': 1, 'Female': 0}\n",
        "    age_cat_mapping = {'Less than 25': 0, '25 - 45': 1, 'Greater than 45': 2}\n",
        "    c_charge_degree_mapping = {'F': 0, 'M': 1}\n",
        "\n",
        "    # Keep records for African-American and Caucasian\n",
        "    df_filtered = df[df['race'].isin(race_mapping.keys())]\n",
        "    print(\"Shape after filtering for race:\", df_filtered.shape)\n",
        "\n",
        "    df_filtered['race'] = df_filtered['race'].map(race_mapping)\n",
        "    df_filtered['sex'] = df_filtered['sex'].map(sex_mapping)\n",
        "    df_filtered['age_cat'] = df_filtered['age_cat'].map(age_cat_mapping)\n",
        "    df_filtered['c_charge_degree'] = df_filtered['c_charge_degree'].map(c_charge_degree_mapping)\n",
        "\n",
        "    return df_filtered\n",
        "\n",
        "processed_data = encode_features(data)\n",
        "\n",
        "# 3. Calculating Length of Stay\n",
        "processed_data['c_jail_in'] = pd.to_datetime(processed_data['c_jail_in'])\n",
        "processed_data['c_jail_out'] = pd.to_datetime(processed_data['c_jail_out'])\n",
        "processed_data['length_of_stay'] = (processed_data['c_jail_out'] - processed_data['c_jail_in']).dt.days\n",
        "\n",
        "# Apply the specified bins to the length of stay\n",
        "processed_data['length_of_stay'] = processed_data['length_of_stay'].apply(\n",
        "    lambda days: 0 if days <= 7 else (2 if days > 90 else 1)\n",
        ")\n",
        "\n",
        "# 5. Processing Prior Crime Counts\n",
        "processed_data['priors_count'] = processed_data['priors_count'].apply(\n",
        "    lambda count: 0 if count == 0 else (2 if count > 3 else 1)\n",
        ")\n",
        "\n",
        "# 6. Handling Duplicate Values\n",
        "final_dataset = processed_data.drop_duplicates()\n",
        "print(\"Final dataset shape after dropping duplicates:\", final_dataset.shape)\n",
        "\n",
        "# 7. # Split the dataset into training, validation, and test sets\n",
        "train_features, remaining_features, train_target, remaining_target = train_test_split(\n",
        "    final_dataset.drop(columns=[\"two_year_recid\"]), final_dataset[\"two_year_recid\"], train_size=5/7.0\n",
        ")\n",
        "validation_features, test_features, validation_target, test_target = train_test_split(\n",
        "    remaining_features, remaining_target, test_size=0.5\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwGDGxxv0yFj",
        "outputId": "9ae27d48-5b4b-4cde-fbab-d4eaeac1b6fc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial dataset shape: (7214, 53)\n",
            "Unique race values in dataset: ['Other' 'African-American' 'Caucasian' 'Hispanic' 'Native American'\n",
            " 'Asian']\n",
            "Shape after filtering for race: (6150, 53)\n",
            "Final dataset shape after dropping duplicates: (6150, 54)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Calculate Mutual Information Scores (Bivariate, vACC, vD)"
      ],
      "metadata": {
        "id": "kwPZqv611LVf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bivariate decomposition of mutual information**:\n",
        "\n",
        "$I(T; R_1, R_2) = UI(T;R_1 \\setminus R_2) + UI(T; R_2 \\setminus R_1) + SI(T; R_1, R_2) + CI(T; R_1, R_2)$\n",
        "\n",
        "mutual information between random variable $T$ and random variables $R_1$ and $R_2$ \\\\\n",
        "= unique information shared between $T$ and $R_1$ but not $R_2$ \\\\\n",
        "$+$ unique information shared between $T$ and $R_2$ but not $R_1$ \\\\\n",
        "$+$ shared information between $T$, $R_1$, and $R_2$ \\\\\n",
        "$+$ synergistic information between $T$, $R_1$, and $R_2$"
      ],
      "metadata": {
        "id": "mtZcFqp01OZw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Generalized formula) \\\\\n",
        "$I(T; R_i) = UI(T; R_i \\setminus R_j) + SI(T; R_1, R_2), \\quad i \\neq j, \\quad i, j \\in \\{1,2\\}$\n",
        "\n",
        "mutual information between $T$ and one of the random variables $R_i$ where $i$ can be either 1 or 2 \\\\\n",
        "= unique information shared between $T$ and $R_i$ but not $R_j$, where $i \\neq j$ and both $i$ and $j$ can be 1 or 2 \\\\\n",
        "$+$ shared information between $T$, $R_1$, and $R_2$"
      ],
      "metadata": {
        "id": "Miec1YvL1Q0t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In our study, $T$ is recidivism (\"whether or not the defendant recidivated within two years\") and $R_i$ is the defendent's race (Caucasian or African-American)."
      ],
      "metadata": {
        "id": "_Rjk_dp71THW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the dataset\n",
        "compas_filtered = data[data['race'].isin(['Caucasian', 'African-American'])]\n",
        "compas_filtered['race'] = compas_filtered['race'].map({'Caucasian': 1, 'African-American': 0})\n",
        "\n",
        "# 0, AA: 3696, 1, Cau: 2454, Total: 6150"
      ],
      "metadata": {
        "id": "zZ3oWz8h1Lvb"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate mutual information score\n",
        "mi_race = mutual_info_score(compas_filtered['two_year_recid'], compas_filtered['race'])\n",
        "print (\"Mutual information between two_year_recid and race is: \", mi_race)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPurkcSU1h90",
        "outputId": "c3ae1f3e-c3b0-4943-f88d-391ae0c0b23e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mutual information between two_year_recid and race is:  0.007054417358854759\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Interpretation*: \\\\\n",
        "+ The mutual information value being close to 0 indicates that the two variables are nearly independent. This means that the race of the defendant, in this context, *does NOT strongly predict or inform* us about the likelihood of recidivism within two years."
      ],
      "metadata": {
        "id": "_mLTgl7n1zcB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy Coefficient (vAcc)** \\\\\n",
        "For a subset of features $X_S$, the accuracy coefficient $vAcc(X_S)$ =\n",
        "\n",
        "$vAcc(X_S) = I(Y; X_S | X_{S_C}) = UI(Y; X_S \\setminus X_{S_C}) + CI(Y; X_S, X_{S_C})$\n",
        "\n",
        "accuracy coefficient for the subset of features $X_S$ \\\\\n",
        "= conditional mutual information between the target variable $Y$ and the features in $X_S$ given the complementary set of features $X_{S_C}$ \\\\\n",
        "= unique information shared between $Y$ and $X_S$ but not with $X_{S_C}$ \\\\\n",
        "$+$ synergistic information between $Y$, $X_S$, and $X_{S_C}$."
      ],
      "metadata": {
        "id": "3GqWWPZ52D7_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In our study, $Y$ is recidivism (\"whether or not the defendant recidivated within two years\") and $X_S$ is the defendent's race (Caucasian or African-American)."
      ],
      "metadata": {
        "id": "QlQY9eiU2Cnm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conditional_mutual_info(df, Y, X_S, X_SC):\n",
        "    if not X_SC:\n",
        "        return mutual_info_score(df[Y], df[X_S])\n",
        "    combined_features = df[[X_S] + X_SC].apply(lambda row: '_'.join(row.values.astype(str)), axis=1)\n",
        "    mi_y_xs_xsc = mutual_info_score(df[Y], combined_features)\n",
        "    complementary_features = df[X_SC].apply(lambda row: '_'.join(row.values.astype(str)), axis=1)\n",
        "    mi_y_xsc = mutual_info_score(df[Y], complementary_features)\n",
        "    cmi = mi_y_xs_xsc - mi_y_xsc\n",
        "    return cmi\n",
        "\n",
        "# Change conditional variables here\n",
        "# Randomly selected\n",
        "X_SC = ['age', 'sex']\n",
        "\n",
        "cmi_score_pure = conditional_mutual_info(compas_filtered, 'two_year_recid', 'race', [])\n",
        "cmi_score_additional = conditional_mutual_info(compas_filtered, 'two_year_recid', 'race', X_SC)\n",
        "\n",
        "print(\"Mutual information between two_year_recid and race is: \", cmi_score_pure)\n",
        "print(\"Conditional mutual information between two_year_recid, race and conditioned on age & sex is: \", cmi_score_additional)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dwye_eJr1_NM",
        "outputId": "c30c3248-8e8e-4c2f-ea1f-750ac0911357"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mutual information between two_year_recid and race is:  0.007054417358854759\n",
            "Conditional mutual information between two_year_recid, race and conditioned on age & sex is:  0.012090642380671007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Notes*: \\\\\n",
        "+ Because we have no complementary $X_{S_C}$ feature subsets, the conditional mutual information score is the same as bivariate information score.\n",
        "+ Can change the conditioned variables in code to see how CMI changes, capturing variables that contribute more information about recidivism that is not captured by race alone.\n",
        "\n",
        "*Interpretation*: \\\\\n",
        "+ A small but positive $vAcc$ indicates that knowing a defendant's race provides a slight amount of information about a defendent's recidivism, but this information is not strong. Therefore race, on its own, is not a highly predictive factor for recidivism.\n",
        "+ When considering the age and sex of the defendant along with their race, the amount of information about recidivism increases."
      ],
      "metadata": {
        "id": "bulk2hsX2Mz6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Discriminatory Effect (vD)**"
      ],
      "metadata": {
        "id": "aRnNiSbX2P4x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The metric $ v^D(X_S) $, as defined, aims to quantify the discriminatory effect of a subset of features $ X_S $ in the context of a protected attribute $ A $. The formula provided is:\n",
        "\n",
        "$ v^D(X_S) = SI(Y; X_S, A) \\times I(X_S; A) \\times I(X_S; A | Y) $\n",
        "\n",
        "Where:\n",
        "\n",
        "- $ SI(Y; X_S, A) $ = Shared Information between the target variable $ Y $ and the combination of features $ X_S $ and the protected attribute $ A $.\n",
        "- $ I(X_S; A) $ = mutual information between the feature subset $ X_S $ and the protected attribute $ A $.\n",
        "- $ I(X_S; A | Y) $ = conditional mutual information between $ X_S $ and $ A $, given $ Y $."
      ],
      "metadata": {
        "id": "nbo39mGQ2SVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def shared_information(df, Y, X_S, A):\n",
        "    if isinstance(X_S, str):\n",
        "        X_S = [X_S]\n",
        "    mi_y_a = mutual_info_score(df[Y], df[A])\n",
        "    joint_X_S_A = df[X_S + [A]].apply(lambda row: '_'.join(row.values.astype(str)), axis=1)\n",
        "    mi_y_joint_x_s_a = mutual_info_score(df[Y], joint_X_S_A)\n",
        "    ui_y_a_x_s = mi_y_a - mi_y_joint_x_s_a\n",
        "    si = mi_y_a - ui_y_a_x_s\n",
        "    return max(si, 0)\n",
        "\n",
        "# conditional mutual information (cmi) calculated previously\n",
        "\n",
        "feature_subset = 'race'\n",
        "protected_attribute = 'race'\n",
        "\n",
        "si_pure = shared_information(compas_filtered, 'two_year_recid', feature_subset, protected_attribute)\n",
        "mi_pure = mutual_info_score(compas_filtered[feature_subset], compas_filtered[protected_attribute])\n",
        "\n",
        "vD_pure = si_pure * mi_pure * cmi_score_pure\n",
        "print(\"Discriminatory impact (vD) of race feature subset is: \", vD_pure)\n",
        "\n",
        "feature_subset = ['age', 'sex']\n",
        "protected_attribute = 'race'\n",
        "\n",
        "si_additional = shared_information(compas_filtered, 'two_year_recid', feature_subset, protected_attribute)\n",
        "\n",
        "combined_features = compas_filtered[feature_subset].apply(lambda row: '_'.join(row.values.astype(str)), axis=1)\n",
        "mi_additional = mutual_info_score(combined_features, compas_filtered[protected_attribute])\n",
        "\n",
        "vD_additional = si_additional * mi_additional * cmi_score_additional\n",
        "print(\"Discriminatory impact (vD) of age, sex feature subset is: \", vD_additional)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdz_p4u42U7d",
        "outputId": "ff3366c7-a9c9-4bee-a4e9-cb29ef906313"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminatory impact (vD) of race feature subset is:  3.347250942628674e-05\n",
            "Discriminatory impact (vD) of age, sex feature subset is:  1.9407422695348022e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Interpretation*: \\\\\n",
        "+ vD for both face and age & sex is relatively small, suggesting that the direct discriminatory impact of race alone, or both age and sex, as measured by this metric, is minimal.\n",
        "+ However, even a small value can be significant, especially in sensitive applications like criminal justice.\n",
        "+ vD for age & sex feature subset is smaller compared to the race subset suggests that the combination of age and sex may have a lesser direct discriminatory impact on recidivism prediction than race alone, according to this metric."
      ],
      "metadata": {
        "id": "rvKVy7H12ZPj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **General insights drawn from score calculations**\n",
        "\n",
        "+ **Race as a Feature**: Race has a slightly higher impact on predicting recidivism compared to age and sex.\n",
        "\n",
        "+ **Combining Race with Age and Sex**: When we consider race together with age and sex, the information about recidivism prediction increases. This means these additional features add useful insights when combined with race.\n",
        "\n",
        "+ **Overall Insight**: Race is more influential in predicting recidivism than the combination of age and sex.\n",
        "\n",
        "(However, the overall impact of these features is limited, meaning that other factors not included in this analysis might be more significant in predicting recidivism. This is a limitations that future analysis on the COMPAS data set can address.)"
      ],
      "metadata": {
        "id": "W-o7Pju32bw8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Choose a Baseline Model\n"
      ],
      "metadata": {
        "id": "kRi0PDJD2cyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating extended dataset\n",
        "extended_dataset = final_dataset\n",
        "\n",
        "# Defining feature sets\n",
        "core_features = ['c_charge_degree', 'age_cat', 'sex', 'race', 'length_of_stay']\n",
        "extended_features_list = [\"priors_count\"] + core_features\n",
        "\n",
        "# Splitting the extended dataset into training, validation, and test sets\n",
        "train_set = extended_dataset[:int(len(extended_dataset) * (5/7))]\n",
        "validation_set = extended_dataset[int(len(extended_dataset) * (6/7)):]\n",
        "test_set = extended_dataset[int(len(extended_dataset) * (5/7)):int(len(extended_dataset) * (6/7))]\n",
        "\n",
        "# Preparing training, testing, and validation data\n",
        "train_data_core = train_set[core_features]\n",
        "train_data_extended = train_set[extended_features_list]\n",
        "train_labels = train_set[\"two_year_recid\"].to_numpy()\n",
        "train_priors_count = train_set[\"priors_count\"]\n",
        "\n",
        "test_data_core = test_set[core_features]\n",
        "test_data_extended = test_set[extended_features_list]\n",
        "test_labels = test_set[\"two_year_recid\"].to_numpy()\n",
        "test_priors_count = test_set[\"priors_count\"]\n",
        "\n",
        "validation_data_core = validation_set[core_features]\n",
        "validation_data_extended = validation_set[extended_features_list]\n",
        "validation_labels = validation_set[\"two_year_recid\"].to_numpy()\n",
        "validation_priors_count = validation_set[\"priors_count\"]\n",
        "\n",
        "# Displaying the first few rows of validation data and its shape\n",
        "print(validation_data_core.head())\n",
        "print(\"Validation data shape:\", np.shape(validation_data_core))\n",
        "\n",
        "# Logistic Regression models\n",
        "clf_priors_count = LogisticRegression().fit(train_data_extended, train_labels)\n",
        "accuracy_priors_count = clf_priors_count.score(validation_data_extended, validation_labels)\n",
        "\n",
        "clf_without_priors_count = LogisticRegression().fit(train_data_core, train_labels)\n",
        "accuracy_without_priors_count = clf_without_priors_count.score(validation_data_core, validation_labels)\n",
        "accuracy_priors_count, accuracy_without_priors_count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUiFmR4H2Guw",
        "outputId": "637738de-d3a4-469e-9881-fc424af09174"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      c_charge_degree  age_cat  sex  race  length_of_stay\n",
            "6187                0        1    1     0               0\n",
            "6189                0        2    1     0               1\n",
            "6190                0        1    1     0               0\n",
            "6191                0        0    1     0               0\n",
            "6192                1        1    1     0               0\n",
            "Validation data shape: (879, 5)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6439135381114903, 0.590443686006826)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clearly, the model with priors count feature has higher accuracy, which means the priors count is a senstive feature, and we need to include it.\n",
        "\n",
        "# 4. Define functions"
      ],
      "metadata": {
        "id": "ETNm2Fyy2n4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clear duplicates\n",
        "final_dataset = processed_data.drop_duplicates()\n",
        "print(\"Final dataset shape after dropping duplicates:\", final_dataset.shape)\n",
        "\n",
        "def uni_values_array(arr):\n",
        "    return [np.unique(arr[:, col]).tolist() for col in range(arr.shape[1])]\n",
        "\n",
        "def power_func(seq):\n",
        "    result = [[]]\n",
        "    for elem in seq:\n",
        "        result.extend([x + [elem] for x in result])\n",
        "    return result\n",
        "\n",
        "def unique_information(array_1, array_2):\n",
        "    assert array_1.shape[0] == array_2.shape[0], \"Arrays must have the same number of rows\"\n",
        "\n",
        "    concated_array = np.concatenate((array_1, array_2), axis=1)\n",
        "    cartesian_product = itertools.product(*uni_values_array(concated_array))\n",
        "    IQ = 0\n",
        "    for i in cartesian_product:\n",
        "        mask = (concated_array == i).all(axis=1)\n",
        "        r1_r2 = np.mean(mask)\n",
        "        r1 = np.mean((array_1 == i[:array_1.shape[1]]).all(axis=1))\n",
        "        r2 = np.mean((array_2 == i[array_1.shape[1]:]).all(axis=1))\n",
        "        IQ_iter = r1_r2 * np.log(r1_r2 / r1) / r1 if r1_r2 > 0 and r1 > 0 and r2 > 0 else 0\n",
        "        IQ += np.abs(IQ_iter)\n",
        "    return IQ\n",
        "\n",
        "def unique_infor_condi(array_1, array_2, conditional):\n",
        "    assert (array_1.shape[0] == array_2.shape[0]) and (array_1.shape[0] == conditional.shape[0]), \"Arrays must have the same number of rows\"\n",
        "\n",
        "    concated_array_all = np.concatenate((array_1, array_2, conditional), axis=1)\n",
        "    cartesian_product = itertools.product(*uni_values_array(concated_array_all))\n",
        "    IQ = 0\n",
        "    for i in cartesian_product:\n",
        "        mask_all = (concated_array_all == i).all(axis=1)\n",
        "        mask_1 = (array_1 == i[:array_1.shape[1]]).all(axis=1)\n",
        "        mask_2_cond = (concated_array_all[:, array_1.shape[1]:] == i[array_1.shape[1]:]).all(axis=1)\n",
        "        r1_r2 = np.mean(mask_all)\n",
        "        r1 = np.mean(mask_1)\n",
        "        r2 = np.mean(mask_2_cond)\n",
        "        r1_given_r2 = np.mean(mask_1[mask_2_cond]) if np.any(mask_2_cond) else 0\n",
        "        IQ_iter = r1_r2 * np.log(r1_r2 / r2) / r1_given_r2 if r1_r2 > 0 and r1 > 0 and r2 > 0 and r1_given_r2 > 0 else 0\n",
        "        IQ += np.abs(IQ_iter)\n",
        "    return IQ\n",
        "\n",
        "def accuracy_coef(y, x_s, x_s_c, A):\n",
        "    conditional = np.concatenate((x_s_c, A), axis=1)\n",
        "    return unique_infor_condi(y, x_s, conditional)\n",
        "\n",
        "def discrimination_coef(y, x_s, A):\n",
        "    x_s_a = np.concatenate((x_s, A), axis=1)\n",
        "    return unique_information(y, x_s_a) * unique_information(x_s, A) * unique_infor_condi(x_s, A, y)\n",
        "\n",
        "def marginal_accuracy_coef(y_train, x_train, A, set_tracker):\n",
        "    n_features = x_train.shape[1]\n",
        "    shapley_value = 0\n",
        "    for sc_idx in itertools.chain.from_iterable(itertools.combinations(range(n_features), r) for r in range(n_features)):\n",
        "        if set_tracker in sc_idx:\n",
        "            continue\n",
        "        coef = math.factorial(len(sc_idx)) * math.factorial(n_features - len(sc_idx) - 1) / math.factorial(n_features)\n",
        "        sc_idx_with_i = list(sc_idx) + [set_tracker]\n",
        "        vTU = accuracy_coef(y_train.reshape(-1, 1), x_train[:, sc_idx_with_i], x_train[:, list(set(range(n_features)) - set(sc_idx_with_i))], A.reshape(-1, 1))\n",
        "        vT = accuracy_coef(y_train.reshape(-1, 1), x_train[:, sc_idx], x_train[:, list(set(range(n_features)) - set(sc_idx))], A.reshape(-1, 1))\n",
        "        shapley_value += coef * (vTU - vT)\n",
        "    return shapley_value\n",
        "\n",
        "def marginal_discrimination_coef(y_train, x_train, A, set_tracker):\n",
        "    n_features = x_train.shape[1]\n",
        "    shapley_value = 0\n",
        "    for sc_idx in itertools.chain.from_iterable(itertools.combinations(range(n_features), r) for r in range(n_features)):\n",
        "        if set_tracker in sc_idx:\n",
        "            continue\n",
        "        coef = math.factorial(len(sc_idx)) * math.factorial(n_features - len(sc_idx) - 1) / math.factorial(n_features)\n",
        "        sc_idx_with_i = list(sc_idx) + [set_tracker]\n",
        "        vTU = discrimination_coef(y_train.reshape(-1, 1), x_train[:, sc_idx_with_i], A.reshape(-1, 1))\n",
        "        vT = discrimination_coef(y_train.reshape(-1, 1), x_train[:, sc_idx], A.reshape(-1, 1))\n",
        "        shapley_value += coef * (vTU - vT)\n",
        "    return shapley_value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAp0bOLl2nVv",
        "outputId": "8a93d349-ade0-4fd6-c49d-f679e8c35caf"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final dataset shape after dropping duplicates: (6150, 54)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Calculate Shapley Value"
      ],
      "metadata": {
        "id": "KVIpgUzk2tyU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Shapley Value"
      ],
      "metadata": {
        "id": "0lwq1hih21Kh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As our ultimate goal is to estimate the marginal impact of each feature, we propose extracting a score for each feature using Shapley value. This is a concept from cooperative game theory that allows assigning values to quantify an individual’s contribution to the game."
      ],
      "metadata": {
        "id": "8tfE6b5622KS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let P denote the power set. Given a characteristic function $v(·) : P((n)) → R$, the Shapley value function\n",
        "$φ(·) : P([n]) → R$ is defined as:\n",
        "$φi = \\sum\\limits_{T ⊆ [n]/i} \\frac{|T|!(n−|T|−1)!}{n!} (v(T ∪{i})−v(T)), ∀i∈[n]$"
      ],
      "metadata": {
        "id": "yuYFmJ9S24Jn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given the characteristic functions $vAcc(·)$ and $vD(·)$, the corresponding Shapley value functions are denoted by $φAcc(·)$ and $φD(·)$ We refer to these as marginal accuracy coefficient and marginal discrimination coefficient, respectively."
      ],
      "metadata": {
        "id": "tCP37lXc26Vt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Shapley values for each feature\n",
        "shapley_acc = []\n",
        "shapley_disc = []\n",
        "features = extended_features_list  # Using the extended set of features\n",
        "for i in range(len(features)):\n",
        "    acc_i = marginal_accuracy_coef(train_labels, train_data_extended[features].to_numpy(), train_data_extended['race'].to_numpy(), i)\n",
        "    disc_i = marginal_discrimination_coef(train_labels, train_data_extended[features].to_numpy(), train_data_extended['race'].to_numpy(), i)\n",
        "    shapley_acc.append(acc_i)\n",
        "    shapley_disc.append(disc_i)\n",
        "\n",
        "# Create a DataFrame to display the Shapley values for each feature\n",
        "shapley = pd.DataFrame(list(zip(features, shapley_acc, shapley_disc)),\n",
        "                       columns=[\"Feature\", \"Accuracy\", 'Discrimination'])\n",
        "\n",
        "# Calculate and display the fairness utility score for different alpha values\n",
        "alpha_values = [0.000001, 0.00001, 0.0001]\n",
        "for alpha in alpha_values:\n",
        "    alpha_df = pd.DataFrame(list(zip(features, shapley_acc, shapley_disc, fairness_utility_score(shapley['Accuracy'], shapley['Discrimination'], alpha))),\n",
        "                            columns=[\"Feature\", \"Accuracy\", 'Discrimination', 'F_score'])\n",
        "    print(f\"Alpha = {alpha}\")\n",
        "    print(alpha_df)"
      ],
      "metadata": {
        "id": "2t2iTi4u2tS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Outputs Below:**\n",
        "\n",
        "\n",
        "> Alpha = 1e-06\n",
        "\n",
        "           Feature            Accuracy       Discrimination       F_score\n",
        "           priors_count       0.000000e+00    8090.544032        -0.008091\n",
        "           c_charge_degree   -9.992007e-17    6308.746881        -0.006309\n",
        "           age_cat           -1.147230e-16    7990.621865        -0.007991\n",
        "           sex                1.295260e-16    6057.511767        -0.006058\n",
        "           race              -2.035409e-16   -36275.753860        0.036276\n",
        "           length_of_stay    -1.406282e-16    7828.329315        -0.007828\n",
        "\n",
        "> Alpha = 1e-05\n",
        "\n",
        "           Feature            Accuracy       Discrimination       F_score\n",
        "           priors_count       0.000000e+00     8090.544032       -0.080905\n",
        "           c_charge_degree   -9.992007e-17     6308.746881       -0.063087\n",
        "           age_cat           -1.147230e-16     7990.621865       -0.079906\n",
        "           sex                1.295260e-16     6057.511767       -0.060575\n",
        "           race              -2.035409e-16   -36275.753860        0.362758\n",
        "           length_of_stay    -1.406282e-16     7828.329315       -0.078283\n",
        "\n",
        "> Alpha = 0.0001\n",
        "\n",
        "           Feature            Accuracy       Discrimination       F_score\n",
        "           priors_count       0.000000e+00     8090.544032       -0.809054\n",
        "           c_charge_degree   -9.992007e-17     6308.746881.      -0.630875\n",
        "           age_cat           -1.147230e-16     7990.621865       -0.799062\n",
        "           sex                1.295260e-16     6057.511767       -0.605751\n",
        "           race              -2.035409e-16   -36275.753860        3.627575\n",
        "           length_of_stay    -1.406282e-16     7828.329315       -0.782833"
      ],
      "metadata": {
        "id": "B8-2ZssQIdz5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calibration"
      ],
      "metadata": {
        "id": "FLmDeYvs2-gI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$P(Ŷ = Y | S = 0) = P(Ŷ = Y | S = 1)$"
      ],
      "metadata": {
        "id": "kKoibA4v3BRM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Remove specific features and train a logistic regression model.\n",
        "train_data_vc = train_data_extended.drop([\"race\"], axis=1)\n",
        "validation_data_vc = validation_data_extended.drop([\"race\"], axis=1)\n",
        "clf_vc = LogisticRegression(random_state=0).fit(train_data_vc, train_labels)\n",
        "accuracy_vc = clf_vc.score(validation_data_vc, validation_labels)\n",
        "\n",
        "train_data_ls = train_data_extended.drop([\"length_of_stay\"], axis=1)\n",
        "validation_data_ls = validation_data_extended.drop([\"length_of_stay\"], axis=1)\n",
        "clf_ls = LogisticRegression(random_state=0).fit(train_data_ls, train_labels)\n",
        "accuracy_ls = clf_ls.score(validation_data_ls, validation_labels)\n",
        "\n",
        "# 2. Define a calibration metric function.\n",
        "def MyCalibration(sensitive_attr, y_pred, y_true):\n",
        "    cau_index = np.where(sensitive_attr == 1)[0]\n",
        "    african_index = np.where(sensitive_attr == 0)[0]\n",
        "\n",
        "    y_pred_cau = y_pred[cau_index]\n",
        "    y_true_cau = y_true[cau_index]\n",
        "    Acc_cau = sum(y_pred_cau == y_true_cau)/len(y_pred_cau)\n",
        "\n",
        "    y_pred_african = y_pred[african_index]\n",
        "    y_true_african = y_true[african_index]\n",
        "    Acc_african = sum(y_pred_african == y_true_african)/len(y_pred_african)\n",
        "\n",
        "    calibration = abs(Acc_cau - Acc_african)\n",
        "    return(calibration)\n",
        "\n",
        "# 3. Evaluate the impact of removing each feature on model performance.\n",
        "Accuracy_lr = []\n",
        "Calibration_lr = []\n",
        "for feature in ['base'] + extended_features_list:\n",
        "    if feature == 'base':\n",
        "        clf = LogisticRegression(random_state=0).fit(train_data_extended, train_labels)\n",
        "    else:\n",
        "        train_data_subset = train_data_extended.drop([feature], axis=1)\n",
        "        clf = LogisticRegression(random_state=0).fit(train_data_subset, train_labels)\n",
        "\n",
        "    test_data_subset = test_data_extended.drop([feature], axis=1) if feature != 'base' else test_data_extended\n",
        "    Accuracy_lr.append(clf.score(test_data_subset, test_labels))\n",
        "    Calibration_lr.append(MyCalibration(test_data_extended['race'], clf.predict(test_data_subset), test_labels))\n",
        "\n",
        "# 4. Create a conclusions DataFrame.\n",
        "Conclusion_lr = pd.DataFrame(list(zip(['base'] + extended_features_list, Accuracy_lr, Calibration_lr)),\n",
        "                             columns=[\"Eliminating Feature\", \"Accuracy\", \"Calibration\"])\n",
        "\n",
        "display(Conclusion_lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "xtm0Wa5j2-C6",
        "outputId": "f9d848fe-2698-4d0c-d0c8-580f71045009"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Eliminating Feature  Accuracy  Calibration\n",
              "0                base  0.653015     0.037191\n",
              "1        priors_count  0.591581     0.045337\n",
              "2     c_charge_degree  0.653015     0.032520\n",
              "3             age_cat  0.623436     0.009118\n",
              "4                 sex  0.653015     0.041862\n",
              "5                race  0.663254     0.031484\n",
              "6      length_of_stay  0.668942     0.045959"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3dd11bab-3b68-457a-9ecb-983b8e843e91\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Eliminating Feature</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Calibration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>base</td>\n",
              "      <td>0.653015</td>\n",
              "      <td>0.037191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>priors_count</td>\n",
              "      <td>0.591581</td>\n",
              "      <td>0.045337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>c_charge_degree</td>\n",
              "      <td>0.653015</td>\n",
              "      <td>0.032520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>age_cat</td>\n",
              "      <td>0.623436</td>\n",
              "      <td>0.009118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sex</td>\n",
              "      <td>0.653015</td>\n",
              "      <td>0.041862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>race</td>\n",
              "      <td>0.663254</td>\n",
              "      <td>0.031484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>length_of_stay</td>\n",
              "      <td>0.668942</td>\n",
              "      <td>0.045959</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3dd11bab-3b68-457a-9ecb-983b8e843e91')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3dd11bab-3b68-457a-9ecb-983b8e843e91 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3dd11bab-3b68-457a-9ecb-983b8e843e91');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-53d1b68b-717c-402b-833e-bb50df6f60de\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-53d1b68b-717c-402b-833e-bb50df6f60de')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-53d1b68b-717c-402b-833e-bb50df6f60de button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simplified Analysis of Feature Combinations in Predictive Model\n",
        "\n",
        "### Combination 1: `priors_count` and `length_of_stay`\n",
        "- **`priors_count`**: Removing this feature significantly decreases accuracy, indicating its importance. Yet, its removal might reduce overfitting or bias.\n",
        "- **`length_of_stay`**: Its removal increases accuracy but also calibration disparity, hinting at its role in introducing subgroup inconsistencies.\n",
        "\n",
        "### Combination 2: `length_of_stay` and `sex`\n",
        "- **`length_of_stay`**: Similar to Combination 1, its removal slightly improves accuracy but raises calibration disparity, suggesting bias introduction.\n",
        "- **`sex`**: Its removal barely affects accuracy but significantly increases calibration disparity, indicating minimal contribution to model bias.\n",
        "\n",
        "### Combination 3: `age_cat` and `length_of_stay`\n",
        "- **`age_cat`**: Lowest calibration disparity. Removing it increases model fairness but decreases accuracy.\n",
        "- **`length_of_stay`**: Consistently introduces bias with lesser impact on accuracy.\n",
        "\n",
        "### Combination 4: `length_of_stay` and `race`\n",
        "- **`length_of_stay`**: As previously noted, introduces bias.\n",
        "- **`race`**: Its removal improves accuracy but also raises calibration disparity. Consider removal for reducing racial influence in sensitive applications like recidivism prediction.\n"
      ],
      "metadata": {
        "id": "ApszJStR3Jyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Final model training and evaluation/trial.\n",
        "train_data_final = train_data_extended.drop([\"length_of_stay\", \"sex\"], axis=1)\n",
        "validation_data_final = validation_data_extended.drop([\"length_of_stay\", \"sex\"], axis=1)\n",
        "clf_final = LogisticRegression(random_state=0).fit(train_data_final, train_labels)\n",
        "accuracy_final = clf_final.score(validation_data_final, validation_labels)\n",
        "display(accuracy_final)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "0cx1sdCU3GrK",
        "outputId": "76713416-62a2-4f72-fd12-30d24763bf45"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.658703071672355"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_final = train_data_extended.drop([\"length_of_stay\", \"priors_count\"], axis=1)\n",
        "validation_data_final = validation_data_extended.drop([\"length_of_stay\", \"priors_count\"], axis=1)\n",
        "clf_final = LogisticRegression(random_state=0).fit(train_data_final, train_labels)\n",
        "accuracy_final = clf_final.score(validation_data_final, validation_labels)\n",
        "display(accuracy_final)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "4QPmntSp3Mo4",
        "outputId": "d69892ea-a574-4a20-e69b-e0faa98db17e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.5915813424345847"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_final = train_data_extended.drop([\"length_of_stay\", \"age_cat\"], axis=1)\n",
        "validation_data_final = validation_data_extended.drop([\"length_of_stay\", \"age_cat\"], axis=1)\n",
        "clf_final = LogisticRegression(random_state=0).fit(train_data_final, train_labels)\n",
        "accuracy_final = clf_final.score(validation_data_final, validation_labels)\n",
        "display(accuracy_final)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "xkagDD9F3N7-",
        "outputId": "cd076386-ee36-4112-ec65-ee3e94c8abfa"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.6484641638225256"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_final = train_data_extended.drop([\"length_of_stay\", \"race\"], axis=1)\n",
        "validation_data_final = validation_data_extended.drop([\"length_of_stay\", \"race\"], axis=1)\n",
        "clf_final = LogisticRegression(random_state=0).fit(train_data_final, train_labels)\n",
        "accuracy_final = clf_final.score(validation_data_final, validation_labels)\n",
        "display(accuracy_final)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "8j0b-dNu3P9l",
        "outputId": "578ad195-903a-4988-ae53-89bddd9c20ee"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.6484641638225256"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_final = train_data_extended.drop([\"length_of_stay\"], axis=1)\n",
        "validation_data_final = validation_data_extended.drop([\"length_of_stay\"], axis=1)\n",
        "clf_final = LogisticRegression(random_state=0).fit(train_data_final, train_labels)\n",
        "accuracy_final = clf_final.score(validation_data_final, validation_labels)\n",
        "display(accuracy_final)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "70CIcfT63SkZ",
        "outputId": "31019409-8d64-4b6c-e4fc-52eaec28c702"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.658703071672355"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusion\n",
        "After testing four combinations and analyzing the recurring feature `length_of_stay`, the best outcome is achieved by simultaneously removing `length_of_stay` and `race`. This approach optimizes model performance, particularly in contexts where reducing racial bias is crucial."
      ],
      "metadata": {
        "id": "XJQk6z3e3XLT"
      }
    }
  ]
}