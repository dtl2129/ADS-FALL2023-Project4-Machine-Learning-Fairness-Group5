{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "NRkQwmS_cdYw"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch as t\n",
        "import torch.nn as nn\n",
        "import warnings\n",
        "import math\n",
        "import itertools\n",
        "import copy\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datetime import datetime, timedelta\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Preproccessing data"
      ],
      "metadata": {
        "id": "yHxv2t0ne2I6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Data Import and Selection\n",
        "columns_required = [\n",
        "    'age', 'c_charge_degree', 'race', 'age_cat', 'sex',\n",
        "    'priors_count', 'is_recid', 'two_year_recid',\n",
        "    'c_jail_in', 'c_jail_out'\n",
        "]\n",
        "dataset = pd.read_csv(\"compas-scores-two-years.csv\", usecols=columns_required)\n",
        "print(\"Initial dataset shape:\", dataset.shape)\n",
        "\n",
        "# Checking the unique values of race to ensure all necessary mappings are accounted for\n",
        "print(\"Unique race values in dataset:\", dataset['race'].unique())\n",
        "\n",
        "# 2. Feature Encoding\n",
        "def encode_features(df):\n",
        "    race_mapping = {'African-American': 0, 'Caucasian': 1}\n",
        "    sex_mapping = {'Male': 1, 'Female': 0}\n",
        "    age_cat_mapping = {'Less than 25': 0, '25 - 45': 1, 'Greater than 45': 2}\n",
        "    c_charge_degree_mapping = {'F': 0, 'M': 1}\n",
        "\n",
        "    # Keep records for African-American and Caucasian\n",
        "    df_filtered = df[df['race'].isin(race_mapping.keys())]\n",
        "    print(\"Shape after filtering for race:\", df_filtered.shape)\n",
        "\n",
        "    df_filtered['race'] = df_filtered['race'].map(race_mapping)\n",
        "    df_filtered['sex'] = df_filtered['sex'].map(sex_mapping)\n",
        "    df_filtered['age_cat'] = df_filtered['age_cat'].map(age_cat_mapping)\n",
        "    df_filtered['c_charge_degree'] = df_filtered['c_charge_degree'].map(c_charge_degree_mapping)\n",
        "\n",
        "    return df_filtered\n",
        "\n",
        "processed_data = encode_features(dataset)\n",
        "\n",
        "# 3. Calculating Length of Stay\n",
        "processed_data['c_jail_in'] = pd.to_datetime(processed_data['c_jail_in'])\n",
        "processed_data['c_jail_out'] = pd.to_datetime(processed_data['c_jail_out'])\n",
        "processed_data['length_of_stay'] = (processed_data['c_jail_out'] - processed_data['c_jail_in']).dt.days\n",
        "\n",
        "# Apply the specified bins to the length of stay\n",
        "processed_data['length_of_stay'] = processed_data['length_of_stay'].apply(\n",
        "    lambda days: 0 if days <= 7 else (2 if days > 90 else 1)\n",
        ")\n",
        "\n",
        "# 5. Processing Prior Crime Counts\n",
        "processed_data['priors_count'] = processed_data['priors_count'].apply(\n",
        "    lambda count: 0 if count == 0 else (2 if count > 3 else 1)\n",
        ")\n",
        "\n",
        "# 6. Handling Duplicate Values\n",
        "final_dataset = processed_data.drop_duplicates()\n",
        "print(\"Final dataset shape after dropping duplicates:\", final_dataset.shape)\n",
        "\n",
        "# 7. # Split the dataset into training, validation, and test sets\n",
        "train_features, remaining_features, train_target, remaining_target = train_test_split(\n",
        "    final_dataset.drop(columns=[\"two_year_recid\"]), final_dataset[\"two_year_recid\"], train_size=5/7.0\n",
        ")\n",
        "validation_features, test_features, validation_target, test_target = train_test_split(\n",
        "    remaining_features, remaining_target, test_size=0.5\n",
        ")\n"
      ],
      "metadata": {
        "id": "omaM_rvWcghs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b10c684-6134-4b23-8c6b-270827e21056"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial dataset shape: (7214, 10)\n",
            "Unique race values in dataset: ['Other' 'African-American' 'Caucasian' 'Hispanic' 'Native American'\n",
            " 'Asian']\n",
            "Shape after filtering for race: (6150, 10)\n",
            "Final dataset shape after dropping duplicates: (6117, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Choose Baseline Model"
      ],
      "metadata": {
        "id": "SSSl1LD1fV4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating extended dataset\n",
        "extended_dataset = final_dataset\n",
        "\n",
        "# Defining feature sets\n",
        "core_features = ['c_charge_degree', 'age_cat', 'sex', 'race', 'length_of_stay']\n",
        "extended_features_list = [\"priors_count\"] + core_features\n",
        "\n",
        "# Splitting the extended dataset into training, validation, and test sets\n",
        "train_set = extended_dataset[:int(len(extended_dataset) * (5/7))]\n",
        "validation_set = extended_dataset[int(len(extended_dataset) * (6/7)):]\n",
        "test_set = extended_dataset[int(len(extended_dataset) * (5/7)):int(len(extended_dataset) * (6/7))]\n",
        "\n",
        "# Preparing training, testing, and validation data\n",
        "train_data_core = train_set[core_features]\n",
        "train_data_extended = train_set[extended_features_list]\n",
        "train_labels = train_set[\"two_year_recid\"].to_numpy()\n",
        "train_priors_count = train_set[\"priors_count\"]\n",
        "\n",
        "test_data_core = test_set[core_features]\n",
        "test_data_extended = test_set[extended_features_list]\n",
        "test_labels = test_set[\"two_year_recid\"].to_numpy()\n",
        "test_priors_count = test_set[\"priors_count\"]\n",
        "\n",
        "validation_data_core = validation_set[core_features]\n",
        "validation_data_extended = validation_set[extended_features_list]\n",
        "validation_labels = validation_set[\"two_year_recid\"].to_numpy()\n",
        "validation_priors_count = validation_set[\"priors_count\"]\n",
        "\n",
        "# Displaying the first few rows of validation data and its shape\n",
        "print(validation_data_core.head())\n",
        "print(\"Validation data shape:\", np.shape(validation_data_core))\n",
        "\n",
        "# Logistic Regression models\n",
        "clf_priors_count = LogisticRegression().fit(train_data_extended, train_labels)\n",
        "accuracy_priors_count = clf_priors_count.score(validation_data_extended, validation_labels)\n",
        "\n",
        "clf_without_priors_count = LogisticRegression().fit(train_data_core, train_labels)\n",
        "accuracy_without_priors_count = clf_without_priors_count.score(validation_data_core, validation_labels)\n",
        "accuracy_priors_count, accuracy_without_priors_count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKO3_3g8fVTj",
        "outputId": "6e593a92-dd21-4583-a6f9-4900ba35208f"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      c_charge_degree  age_cat  sex  race  length_of_stay\n",
            "6184                1        1    0     0               0\n",
            "6186                0        0    1     1               1\n",
            "6187                0        1    1     0               0\n",
            "6189                0        2    1     0               1\n",
            "6190                0        1    1     0               0\n",
            "Validation data shape: (874, 5)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6556064073226545, 0.5983981693363845)"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clearly, the model with priors count feature has higher accuracy, which means the priors count is a senstive feature, and we need to include it.\n",
        "\n",
        "# 3. Define functions"
      ],
      "metadata": {
        "id": "o-x3rH_uf0q1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clear duplicates\n",
        "final_dataset = processed_data.drop_duplicates()\n",
        "print(\"Final dataset shape after dropping duplicates:\", final_dataset.shape)\n",
        "\n",
        "def uni_values_array(arr):\n",
        "    return [np.unique(arr[:, col]).tolist() for col in range(arr.shape[1])]\n",
        "\n",
        "def power_func(seq):\n",
        "    result = [[]]\n",
        "    for elem in seq:\n",
        "        result.extend([x + [elem] for x in result])\n",
        "    return result\n",
        "\n",
        "def unique_information(array_1, array_2):\n",
        "    assert array_1.shape[0] == array_2.shape[0], \"Arrays must have the same number of rows\"\n",
        "\n",
        "    concated_array = np.concatenate((array_1, array_2), axis=1)\n",
        "    cartesian_product = itertools.product(*uni_values_array(concated_array))\n",
        "    IQ = 0\n",
        "    for i in cartesian_product:\n",
        "        mask = (concated_array == i).all(axis=1)\n",
        "        r1_r2 = np.mean(mask)\n",
        "        r1 = np.mean((array_1 == i[:array_1.shape[1]]).all(axis=1))\n",
        "        r2 = np.mean((array_2 == i[array_1.shape[1]:]).all(axis=1))\n",
        "        IQ_iter = r1_r2 * np.log(r1_r2 / r1) / r1 if r1_r2 > 0 and r1 > 0 and r2 > 0 else 0\n",
        "        IQ += np.abs(IQ_iter)\n",
        "    return IQ\n",
        "\n",
        "def unique_infor_condi(array_1, array_2, conditional):\n",
        "    assert (array_1.shape[0] == array_2.shape[0]) and (array_1.shape[0] == conditional.shape[0]), \"Arrays must have the same number of rows\"\n",
        "\n",
        "    concated_array_all = np.concatenate((array_1, array_2, conditional), axis=1)\n",
        "    cartesian_product = itertools.product(*uni_values_array(concated_array_all))\n",
        "    IQ = 0\n",
        "    for i in cartesian_product:\n",
        "        mask_all = (concated_array_all == i).all(axis=1)\n",
        "        mask_1 = (array_1 == i[:array_1.shape[1]]).all(axis=1)\n",
        "        mask_2_cond = (concated_array_all[:, array_1.shape[1]:] == i[array_1.shape[1]:]).all(axis=1)\n",
        "        r1_r2 = np.mean(mask_all)\n",
        "        r1 = np.mean(mask_1)\n",
        "        r2 = np.mean(mask_2_cond)\n",
        "        r1_given_r2 = np.mean(mask_1[mask_2_cond]) if np.any(mask_2_cond) else 0\n",
        "        IQ_iter = r1_r2 * np.log(r1_r2 / r2) / r1_given_r2 if r1_r2 > 0 and r1 > 0 and r2 > 0 and r1_given_r2 > 0 else 0\n",
        "        IQ += np.abs(IQ_iter)\n",
        "    return IQ\n",
        "\n",
        "def accuracy_coef(y, x_s, x_s_c, A):\n",
        "    conditional = np.concatenate((x_s_c, A), axis=1)\n",
        "    return unique_infor_condi(y, x_s, conditional)\n",
        "\n",
        "def discrimination_coef(y, x_s, A):\n",
        "    x_s_a = np.concatenate((x_s, A), axis=1)\n",
        "    return unique_information(y, x_s_a) * unique_information(x_s, A) * unique_infor_condi(x_s, A, y)\n",
        "\n",
        "def marginal_accuracy_coef(y_train, x_train, A, set_tracker):\n",
        "    n_features = x_train.shape[1]\n",
        "    shapley_value = 0\n",
        "    for sc_idx in itertools.chain.from_iterable(itertools.combinations(range(n_features), r) for r in range(n_features)):\n",
        "        if set_tracker in sc_idx:\n",
        "            continue\n",
        "        coef = math.factorial(len(sc_idx)) * math.factorial(n_features - len(sc_idx) - 1) / math.factorial(n_features)\n",
        "        sc_idx_with_i = list(sc_idx) + [set_tracker]\n",
        "        vTU = accuracy_coef(y_train.reshape(-1, 1), x_train[:, sc_idx_with_i], x_train[:, list(set(range(n_features)) - set(sc_idx_with_i))], A.reshape(-1, 1))\n",
        "        vT = accuracy_coef(y_train.reshape(-1, 1), x_train[:, sc_idx], x_train[:, list(set(range(n_features)) - set(sc_idx))], A.reshape(-1, 1))\n",
        "        shapley_value += coef * (vTU - vT)\n",
        "    return shapley_value\n",
        "\n",
        "def marginal_discrimination_coef(y_train, x_train, A, set_tracker):\n",
        "    n_features = x_train.shape[1]\n",
        "    shapley_value = 0\n",
        "    for sc_idx in itertools.chain.from_iterable(itertools.combinations(range(n_features), r) for r in range(n_features)):\n",
        "        if set_tracker in sc_idx:\n",
        "            continue\n",
        "        coef = math.factorial(len(sc_idx)) * math.factorial(n_features - len(sc_idx) - 1) / math.factorial(n_features)\n",
        "        sc_idx_with_i = list(sc_idx) + [set_tracker]\n",
        "        vTU = discrimination_coef(y_train.reshape(-1, 1), x_train[:, sc_idx_with_i], A.reshape(-1, 1))\n",
        "        vT = discrimination_coef(y_train.reshape(-1, 1), x_train[:, sc_idx], A.reshape(-1, 1))\n",
        "        shapley_value += coef * (vTU - vT)\n",
        "    return shapley_value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zz6u-m_XcpT_",
        "outputId": "1889bfc1-ed07-48e9-a039-55a061404c0f"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final dataset shape after dropping duplicates: (6117, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Calculate Shapley Value"
      ],
      "metadata": {
        "id": "SvSlqkkFi5YB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Shapley values for each feature\n",
        "shapley_acc = []\n",
        "shapley_disc = []\n",
        "features = extended_features_list  # Using the extended set of features\n",
        "for i in range(len(features)):\n",
        "    acc_i = marginal_accuracy_coef(train_labels, train_data_extended[features].to_numpy(), train_data_extended['race'].to_numpy(), i)\n",
        "    disc_i = marginal_discrimination_coef(train_labels, train_data_extended[features].to_numpy(), train_data_extended['race'].to_numpy(), i)\n",
        "    shapley_acc.append(acc_i)\n",
        "    shapley_disc.append(disc_i)\n",
        "\n",
        "# Create a DataFrame to display the Shapley values for each feature\n",
        "shapley = pd.DataFrame(list(zip(features, shapley_acc, shapley_disc)),\n",
        "                       columns=[\"Feature\", \"Accuracy\", 'Discrimination'])\n",
        "\n",
        "# Calculate and display the fairness utility score for different alpha values\n",
        "alpha_values = [0.000001, 0.00001, 0.0001]\n",
        "for alpha in alpha_values:\n",
        "    alpha_df = pd.DataFrame(list(zip(features, shapley_acc, shapley_disc, fairness_utility_score(shapley['Accuracy'], shapley['Discrimination'], alpha))),\n",
        "                            columns=[\"Feature\", \"Accuracy\", 'Discrimination', 'F_score'])\n",
        "    print(f\"Alpha = {alpha}\")\n",
        "    print(alpha_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZVLdV1bcug_",
        "outputId": "37c4cbf6-8f31-4f7d-a8c7-18eb3ce5af8c"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alpha = 1e-06\n",
            "           Feature      Accuracy  Discrimination   F_score\n",
            "0     priors_count  0.000000e+00     8090.544032 -0.008091\n",
            "1  c_charge_degree -9.992007e-17     6308.746881 -0.006309\n",
            "2          age_cat -1.147230e-16     7990.621865 -0.007991\n",
            "3              sex  1.295260e-16     6057.511767 -0.006058\n",
            "4             race -2.035409e-16   -36275.753860  0.036276\n",
            "5   length_of_stay -1.406282e-16     7828.329315 -0.007828\n",
            "Alpha = 1e-05\n",
            "           Feature      Accuracy  Discrimination   F_score\n",
            "0     priors_count  0.000000e+00     8090.544032 -0.080905\n",
            "1  c_charge_degree -9.992007e-17     6308.746881 -0.063087\n",
            "2          age_cat -1.147230e-16     7990.621865 -0.079906\n",
            "3              sex  1.295260e-16     6057.511767 -0.060575\n",
            "4             race -2.035409e-16   -36275.753860  0.362758\n",
            "5   length_of_stay -1.406282e-16     7828.329315 -0.078283\n",
            "Alpha = 0.0001\n",
            "           Feature      Accuracy  Discrimination   F_score\n",
            "0     priors_count  0.000000e+00     8090.544032 -0.809054\n",
            "1  c_charge_degree -9.992007e-17     6308.746881 -0.630875\n",
            "2          age_cat -1.147230e-16     7990.621865 -0.799062\n",
            "3              sex  1.295260e-16     6057.511767 -0.605751\n",
            "4             race -2.035409e-16   -36275.753860  3.627575\n",
            "5   length_of_stay -1.406282e-16     7828.329315 -0.782833\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Remove specific features and train a logistic regression model.\n",
        "train_data_vc = train_data_extended.drop([\"race\"], axis=1)\n",
        "validation_data_vc = validation_data_extended.drop([\"race\"], axis=1)\n",
        "clf_vc = LogisticRegression(random_state=0).fit(train_data_vc, train_labels)\n",
        "accuracy_vc = clf_vc.score(validation_data_vc, validation_labels)\n",
        "\n",
        "train_data_ls = train_data_extended.drop([\"length_of_stay\"], axis=1)\n",
        "validation_data_ls = validation_data_extended.drop([\"length_of_stay\"], axis=1)\n",
        "clf_ls = LogisticRegression(random_state=0).fit(train_data_ls, train_labels)\n",
        "accuracy_ls = clf_ls.score(validation_data_ls, validation_labels)\n",
        "\n",
        "# 2. Define a calibration metric function.\n",
        "def MyCalibration(sensitive_attr, y_pred, y_true):\n",
        "    cau_index = np.where(sensitive_attr == 1)[0]\n",
        "    african_index = np.where(sensitive_attr == 0)[0]\n",
        "\n",
        "    y_pred_cau = y_pred[cau_index]\n",
        "    y_true_cau = y_true[cau_index]\n",
        "    Acc_cau = sum(y_pred_cau == y_true_cau)/len(y_pred_cau)\n",
        "\n",
        "    y_pred_african = y_pred[african_index]\n",
        "    y_true_african = y_true[african_index]\n",
        "    Acc_african = sum(y_pred_african == y_true_african)/len(y_pred_african)\n",
        "\n",
        "    calibration = abs(Acc_cau - Acc_african)\n",
        "    return(calibration)\n",
        "\n",
        "# 3. Evaluate the impact of removing each feature on model performance.\n",
        "Accuracy_lr = []\n",
        "Calibration_lr = []\n",
        "for feature in ['base'] + extended_features_list:\n",
        "    if feature == 'base':\n",
        "        clf = LogisticRegression(random_state=0).fit(train_data_extended, train_labels)\n",
        "    else:\n",
        "        train_data_subset = train_data_extended.drop([feature], axis=1)\n",
        "        clf = LogisticRegression(random_state=0).fit(train_data_subset, train_labels)\n",
        "\n",
        "    test_data_subset = test_data_extended.drop([feature], axis=1) if feature != 'base' else test_data_extended\n",
        "    Accuracy_lr.append(clf.score(test_data_subset, test_labels))\n",
        "    Calibration_lr.append(MyCalibration(test_data_extended['race'], clf.predict(test_data_subset), test_labels))\n",
        "\n",
        "# 4. Create a conclusions DataFrame.\n",
        "Conclusion_lr = pd.DataFrame(list(zip(['base'] + extended_features_list, Accuracy_lr, Calibration_lr)),\n",
        "                             columns=[\"Eliminating Feature\", \"Accuracy\", \"Calibration\"])\n",
        "\n",
        "display(Conclusion_lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "GUZfFRZ3jooJ",
        "outputId": "26f74713-7cb2-4017-b644-3ba7ff37d028"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Eliminating Feature  Accuracy  Calibration\n",
              "0                base  0.653318     0.037871\n",
              "1        priors_count  0.592677     0.043629\n",
              "2     c_charge_degree  0.654462     0.035161\n",
              "3             age_cat  0.624714     0.006944\n",
              "4                 sex  0.652174     0.045271\n",
              "5                race  0.663616     0.032241\n",
              "6      length_of_stay  0.668192     0.044852"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-84f068d7-16d4-4549-bcf3-9f21e4280ff2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Eliminating Feature</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Calibration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>base</td>\n",
              "      <td>0.653318</td>\n",
              "      <td>0.037871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>priors_count</td>\n",
              "      <td>0.592677</td>\n",
              "      <td>0.043629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>c_charge_degree</td>\n",
              "      <td>0.654462</td>\n",
              "      <td>0.035161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>age_cat</td>\n",
              "      <td>0.624714</td>\n",
              "      <td>0.006944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sex</td>\n",
              "      <td>0.652174</td>\n",
              "      <td>0.045271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>race</td>\n",
              "      <td>0.663616</td>\n",
              "      <td>0.032241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>length_of_stay</td>\n",
              "      <td>0.668192</td>\n",
              "      <td>0.044852</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-84f068d7-16d4-4549-bcf3-9f21e4280ff2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-84f068d7-16d4-4549-bcf3-9f21e4280ff2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-84f068d7-16d4-4549-bcf3-9f21e4280ff2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0474fe19-3d52-4f3f-b085-3b9c2782a8d7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0474fe19-3d52-4f3f-b085-3b9c2782a8d7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0474fe19-3d52-4f3f-b085-3b9c2782a8d7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simplified Analysis of Feature Combinations in Predictive Model\n",
        "\n",
        "### Combination 1: `priors_count` and `length_of_stay`\n",
        "- **`priors_count`**: Removing this feature significantly decreases accuracy, indicating its importance. Yet, its removal might reduce overfitting or bias.\n",
        "- **`length_of_stay`**: Its removal increases accuracy but also calibration disparity, hinting at its role in introducing subgroup inconsistencies.\n",
        "\n",
        "### Combination 2: `length_of_stay` and `sex`\n",
        "- **`length_of_stay`**: Similar to Combination 1, its removal slightly improves accuracy but raises calibration disparity, suggesting bias introduction.\n",
        "- **`sex`**: Its removal barely affects accuracy but significantly increases calibration disparity, indicating minimal contribution to model bias.\n",
        "\n",
        "### Combination 3: `age_cat` and `length_of_stay`\n",
        "- **`age_cat`**: Lowest calibration disparity. Removing it increases model fairness but decreases accuracy.\n",
        "- **`length_of_stay`**: Consistently introduces bias with lesser impact on accuracy.\n",
        "\n",
        "### Combination 4: `length_of_stay` and `race`\n",
        "- **`length_of_stay`**: As previously noted, introduces bias.\n",
        "- **`race`**: Its removal improves accuracy but also raises calibration disparity. Consider removal for reducing racial influence in sensitive applications like recidivism prediction.\n"
      ],
      "metadata": {
        "id": "ICDQoasftFo4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Final model training and evaluation/trial.\n",
        "train_data_final = train_data_extended.drop([\"length_of_stay\", \"sex\"], axis=1)\n",
        "validation_data_final = validation_data_extended.drop([\"length_of_stay\", \"sex\"], axis=1)\n",
        "clf_final = LogisticRegression(random_state=0).fit(train_data_final, train_labels)\n",
        "accuracy_final = clf_final.score(validation_data_final, validation_labels)\n",
        "display(accuracy_final)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "fKhdWHOfrJGe",
        "outputId": "b196f455-5994-492b-aa75-a85929ff1b25"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.6590389016018307"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_final = train_data_extended.drop([\"length_of_stay\", \"priors_count\"], axis=1)\n",
        "validation_data_final = validation_data_extended.drop([\"length_of_stay\", \"priors_count\"], axis=1)\n",
        "clf_final = LogisticRegression(random_state=0).fit(train_data_final, train_labels)\n",
        "accuracy_final = clf_final.score(validation_data_final, validation_labels)\n",
        "display(accuracy_final)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "P4NzmwR_sKw-",
        "outputId": "f0f0392e-4585-4f1b-fc4d-06034046c776"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.5938215102974829"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_final = train_data_extended.drop([\"length_of_stay\", \"age_cat\"], axis=1)\n",
        "validation_data_final = validation_data_extended.drop([\"length_of_stay\", \"age_cat\"], axis=1)\n",
        "clf_final = LogisticRegression(random_state=0).fit(train_data_final, train_labels)\n",
        "accuracy_final = clf_final.score(validation_data_final, validation_labels)\n",
        "display(accuracy_final)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Fvfapg8OtnYc",
        "outputId": "4929d96b-8ba1-49e5-8003-c0e513e391dc"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.6521739130434783"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_final = train_data_extended.drop([\"length_of_stay\", \"race\"], axis=1)\n",
        "validation_data_final = validation_data_extended.drop([\"length_of_stay\", \"race\"], axis=1)\n",
        "clf_final = LogisticRegression(random_state=0).fit(train_data_final, train_labels)\n",
        "accuracy_final = clf_final.score(validation_data_final, validation_labels)\n",
        "display(accuracy_final)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "XP4bvVfOtoju",
        "outputId": "81bd6672-16cb-4390-b545-6f664969ed16"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.665903890160183"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_final = train_data_extended.drop([\"length_of_stay\"], axis=1)\n",
        "validation_data_final = validation_data_extended.drop([\"length_of_stay\"], axis=1)\n",
        "clf_final = LogisticRegression(random_state=0).fit(train_data_final, train_labels)\n",
        "accuracy_final = clf_final.score(validation_data_final, validation_labels)\n",
        "display(accuracy_final)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "1bC6h7SYuWfk",
        "outputId": "7f841391-aed8-410a-c14f-b583e5bf8a47"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.6590389016018307"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusion\n",
        "After testing four combinations and analyzing the recurring feature `length_of_stay`, the best outcome is achieved by simultaneously removing `length_of_stay` and `race`. This approach optimizes model performance, particularly in contexts where reducing racial bias is crucial."
      ],
      "metadata": {
        "id": "ypsDu18juZcq"
      }
    }
  ]
}